# -*- coding: utf-8 -*-
"""ir_indexing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zLI85i2tKOMl8-oGDuly9XU4Qpgp-5E6
"""


import os
import pysolr
import requests
import pandas as pd
import pickle
import json

CORE_NAME = "IRF23P1"
VM_IP = "localhost"

def delete_core(core=CORE_NAME):
    print(os.system('sudo su - solr -c "/opt/solr/bin/solr delete -c {core}"'.format(core=core)))


def create_core(core=CORE_NAME):
    print(os.system(
        'sudo su - solr -c "/opt/solr/bin/solr create -c {core} -n data_driven_schema_configs"'.format(
            core=core)))

class Indexer:
    def __init__(self):
        self.solr_url = f'http://{VM_IP}:8983/solr/'
        self.connection = pysolr.Solr(self.solr_url + CORE_NAME, always_commit=True, timeout=5000000)

    def do_initial_setup(self):
        delete_core()
        create_core()

    def create_documents(self, docs):
        print(self.connection.add(docs))

    def add_fields(self):
        data = {
            "add-field": [
                {
                    "name": "revision_id",
                    "type": "string",
                    "indexed": True,
                    "multiValued": False
                },
                {
                    "name": "title",
                    "type": "string",
                    "multiValued": False
                },
                {
                    "name": "summary",
                    "type": "string",
                    "multiValued": False
                },
                {
                    "name": "url",
                    "type": "string",
                    "multiValued": False
                },
                {
                    "name": "topic",
                    "type": "string",
                    "multiValued": False
                },

            ]
        }


        print(requests.post(self.solr_url + CORE_NAME + "/schema", json=data).json())

with open('Akanksh_Data.json','r') as file:
  data = json.load(file)
df = pd.DataFrame(data)

# Setting up the core and adding the fields
i = Indexer()
i.do_initial_setup()
i.add_fields()

# Index the sample dataset
collection = df.to_dict('records')
i.create_documents(collection)
